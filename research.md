---
layout: page
title: research
---

I currently work on machine learning methods for *data-driven design*, the design of novel objects with desired properties, such as proteins, molecules, or materials, in a way that is learned purely from data. How should we leverage generative and predictive modeling for this goal, and how does that differ from traditional uses of these technologies? I am particularly interested in these questions as they apply to the design of proteins with improved functions.

I also maintain an interest in applications of machine learning for exploring life in our last great frontier, the ocean.

## preprints

- Chloe Hsu, Hunter Nisonoff, **Clara Fannjiang**, Jennifer Listgarten. A systematic assessment of methods for combining evolutionary and assay-labelled data for protein fitness prediction. [bioRxiv](https://www.biorxiv.org/content/10.1101/2021.03.28.437402v1){: .btn}

- Akosua Busia, George E. Dahl, **Clara Fannjiang**, David H. Alexander, Elizabeth Dorfman, Ryan Poplin, Cory Y. McLean, Pi-Chuan Chang, and Mark DePristo. A deep learning approach to pattern recognition for short DNA. [bioRxiv](https://www.biorxiv.org/content/early/2018/06/22/353474){: .btn}

## refereed conferences

- Ghassen Jerfel\*, Serena Wang\*, **Clara Fannjiang**, Katherine Heller, Yian Ma, Michael Jordan. Variational refinement for importance sampling using the forward Kullback-Leibler divergence. Advances in Approximate Bayesian Inference (AABI) 2021.

- **Clara Fannjiang** and Jennifer Listgarten. Autofocused oracles for model-based design. NeurIPS 2020. [arXiv](https://arxiv.org/abs/2006.08052){: .btn} [pre-proceedings](https://papers.nips.cc/paper/2020/hash/972cda1e62b72640cb7ac702714a115f-Abstract.html){: .btn} [code](https://github.com/clarafy/autofocused-oracles){: .btn}

- David H. Brookes, Akosua Busia, **Clara Fannjiang**, Kevin Murphy, and Jennifer Listgarten. A view of estimation of distribution algorithms through the lens of expectation-maximization. GECCO 2020. [proceedings](https://dl.acm.org/doi/10.1145/3377929.3389938){: .btn} [arXiv (extended version)](https://arxiv.org/abs/1905.10474){: .btn}

- Katherine Lee, Orhan Firat, Ashish Agarwal, **Clara Fannjiang**, and David Sussillo. Hallucinations in neural machine translation. NeurIPS 2018 Workshop on Interpretability and Robustness for Audio, Speech, and Language. [PDF](/research/neurips_irasl_2018.pdf){: .btn}

## journals

- I. Masmitja, J. Navarro, S. Gomariz,  J. Aguzzi, B. Kieft, T. Oâ€™Reilly, K. Katija, P. J. Bouvet, **C. Fannjiang**, M. Vigo, P. Puig, A. Alcocer, G. Vallicrosa, N. Palomeras, M. Carreras, J. Del-Rio, J. B. Company. 2020. Mobile robotic platforms for the acoustic tracking of deep-sea demersal fishery resources. *Science Robotics*, Vol. 5, Issue 48, eabc3701. [PDF](/research/scirob_2020.pdf){: .btn} [publication](https://robotics.sciencemag.org/content/5/48/eabc3701){: .btn}

- **Clara Fannjiang**, T. Aran Mooney, Seth Cones, David Mann, K. Alex Shorter, and Kakani Katija. 2019. Augmenting biologging with supervised machine learning to study *in situ* behavior of the medusa *Chrysaora fuscescens*. *Journal of Experimental Biology*, 222, jeb207654. [PDF](/research/jeb_2019_wsi.pdf){: .btn} [publication](https://jeb.biologists.org/content/222/16/jeb207654){: .btn} [jellyfish footage](http://movie.biologists.com/video/10.1242/jeb.207654/video-1){: .btn} [code](https://bitbucket.org/mbari/jellymove/src/master/){: .btn}

- **Clara Fannjiang**. 2013. Optimal arrays for compressed sensing in snapshot-mode radio interferometry. *Astronomy & Astrophysics*, 559, A73. [PDF](/research/aa_2013.pdf){: .btn} [publication](https://www.aanda.org/articles/aa/full_html/2013/11/aa21079-13/aa21079-13.html){: .btn}

\* equal contribution

<br>

<figure class="align-center">
  <a href="#"><img src="{{ '/images/benthocodon_hyalinus_med.png' | absolute_url }}" alt=""></a>
  <figcaption><em>Benthocodon hyalinus</em>, after photo by K. Raskoff in <a href="https://www.frontiersin.org/articles/10.3389/fmars.2019.00798/full">Matsumoto et al. (2020)</a>.</figcaption>
</figure> 

